{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788d0152",
   "metadata": {},
   "source": [
    "Deploy endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d5543e",
   "metadata": {},
   "source": [
    "Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "import os\n",
    "import matplotlib\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.predictor import Predictor\n",
    "# Define bucket and model location\n",
    "bucket = \"thibaut-test-inference-cbramod\"\n",
    "key = \"cbramod/model.tar.gz\"\n",
    "model_data = f\"s3://{bucket}/{key}\"\n",
    "\n",
    "# Get current role and region\n",
    "role = get_execution_role()\n",
    "region = sagemaker.Session().boto_region_name\n",
    "\n",
    "print(\"✅ Role:\", role)\n",
    "print(\"✅ Region:\", region)\n",
    "print(\"✅ Model S3 path:\", model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02543a15",
   "metadata": {},
   "source": [
    "Step 2: Define the PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = PyTorchModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=None,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    framework_version=\"2.0.0\",\n",
    "    py_version=\"py310\",\n",
    "    env={\"RAW_RECORDINGS_BUCKET\": \"idn-dev-raw-recordings-bucket\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca1ff2",
   "metadata": {},
   "source": [
    "Step 3: Define Serverless Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=6144,\n",
    "    max_concurrency=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b613c220",
   "metadata": {},
   "source": [
    "Step 4: Deploy to SageMaker Serverless Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"eeg-serverless-endpoint\"\n",
    "\n",
    "predictor = pytorch_model.deploy(\n",
    "    endpoint_name=\"eeg-serverless-endpoint\",\n",
    "    serverless_inference_config=serverless_config,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "print(f\"✅ Endpoint deployed: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9462e47e",
   "metadata": {},
   "source": [
    "Step 5: Test the Endpoint with Sample Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "predictor = Predictor(\n",
    "    endpoint_name=\"eeg-serverless-endpoint\",\n",
    "    serializer=JSONSerializer()\n",
    ")\n",
    "os.environ[\"RAW_RECORDINGS_BUCKET\"] = \"idn-dev-raw-recordings-bucket\"\n",
    "\n",
    "# Input\n",
    "sample_input = {\n",
    "    \"bucket_name\": \"idn-dev-raw-recordings-bucket\",\n",
    "    \"userId\": \"036d5eb6-e177-475a-bb64-5c09e51062a7\",\n",
    "    \"deviceId\": \"F9-79-78-54-CA-15\",\n",
    "    \"recordingId\": \"1707409115815\",\n",
    "    \"orig_sfreq\": 250\n",
    "}\n",
    "\n",
    "# Predict\n",
    "response = predictor.predict(sample_input)\n",
    "\n",
    "# ✅ Decode + parse\n",
    "if isinstance(response, bytes):\n",
    "    response = response.decode()\n",
    "\n",
    "parsed = json.loads(response)\n",
    "print(\"✅ Clean Prediction:\", parsed[\"prediction\"])\n",
    "print(len(parsed[\"prediction\"]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
